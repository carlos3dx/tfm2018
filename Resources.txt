Instalar pip3
https://askubuntu.com/a/412179

Librería lda 1.0.5
https://pypi.python.org/pypi/lda

ehm... parece que pycharm los instala para el proyecto...
pero es independiente del pc

Se requiere también el corpus de stopwords

https://stackoverflow.com/a/30822962/1346287

Brown corpus, importante, de cara a las categorías
http://www.nltk.org/book/ch02.html

LDA en python
https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html

Wordnet
https://wordnet.princeton.edu/wordnet/download/
IMPORTANTE SI SE USA HAY QUE CITARLO BIEN POR TEMAS DE LICENCIA
https://wordnet.princeton.edu/wordnet/citing-wordnet/

Dominios extra para WN y para el propio WN en NLTK que no trae nada
https://stackoverflow.com/questions/21902411/how-to-get-domain-of-words-using-wordnet-in-python
    http://wndomains.fbk.eu/

Su fruta madre, lo de fbk está mega desactualizado, en su lugar utilizar los de
http://compling.hss.ntu.edu.sg/omw/
Tampoco me sirve, voy a tener que hacerlo a mano


trabajar con synsets, ver los más frecuentes y luego, sacar los comunes y /o relevantes y luego sacar el dominio


parece ser que tengo que pillar las categorias de wiktionary y esto me es útil
https://kodingnotes.wordpress.com/2014/12/03/parsing-wikipedia-page-hierarchy/

https://pypi.python.org/pypi/PyMySQL
http://pymysql.readthedocs.io/en/latest/modules/cursors.html

Nota, para Wiktionary, filtrar categorías de más de 1000 páginas en lugar de 5000, que si no hay un par de categorías que se van de madre

De momento sólo páginas normales, sin redirecciones

hay que descargar las stopwords

MYsql es lentísimo con shove!!!!!!!!!!!!!!!

Hacer implementación "de juguete" para probar que funciona, demostrar que funciona y mostrar de forma sencilla en la presentación que funciona

Incluir en la memoria los problemas relacionados con los conjuntos de LDA que eran todos iguales (a modo de demostrar que se ha realizado un trabajo)

Aunque exista espació libre suficiente en disco, si se acaban los inodes por generar tanto archivo pequeño, el sistema da error de "espacio insuficiente", explicar lo sucedido con el ssd

Total pages processed =  18106146
Traceback (most recent call last):
  File "/home/carlos3dx/Almacen/tfm/tfm2018/venv/lib/python3.4/site-packages/shove/base.py", line 120, in __setitem__
    with open(self._key_to_file(key), 'wb') as item:
OSError: [Errno 36] File name too long: '/home/carlos3dx/Extra/tfm/dictionaries_enwiki/titles/frozenset___%CE%B3%E1%BD%B0%CF%81____%E1%BC%94%CF%86%CE%B7____%CF%80%CF%8C%CE%BB%CE%B9%CE%BD____%E1%BC%90%CE%BB%CF%80%E1%BD%B6%CF%82____%CE%BA%CE%B1%CE%BA%CE%AC____%E1%BC%94%CE%BB%CE%B1%CE%B2%CE%BF%CE%BD____%CE%BF%E1%BD%90%CE%BA____%CE%AC%CE%BB%CE%BB%CE%B1___'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/carlos3dx/Almacen/tfm/tfm2018/src/process_articles.py", line 162, in <module>

  File "/home/carlos3dx/Almacen/tfm/tfm2018/venv/lib/python3.4/site-packages/shove/core.py", line 74, in sync
    self._store.update(self._buffer)
  File "/home/carlos3dx/Almacen/tfm/tfm2018/venv/lib/python3.4/_collections_abc.py", line 592, in update
    self[key] = other[key]
  File "/home/carlos3dx/Almacen/tfm/tfm2018/venv/lib/python3.4/site-packages/shove/base.py", line 123, in __setitem__
    raise KeyError(key)
KeyError: 'frozenset___γὰρ____ἔφη____πόλιν____ἐλπὶς____κακά____ἔλαβον____οὐκ____άλλα___'

'frozenset___\xce\xb3\xe1\xbd\xb0\xcf\x81____\xe1\xbc\x94\xcf\x86\xce\xb7____\xcf\x80\xcf\x8c\xce\xbb\xce\xb9\xce\xbd____\xe1\xbc\x90\xce\xbb\xcf\x80\xe1\xbd\xb6\xcf\x82____\xce\xba\xce\xb1\xce\xba\xce\xac____\xe1\xbc\x94\xce\xbb\xce\xb1\xce\xb2\xce\xbf\xce\xbd____\xce\xbf\xe1\xbd\x90\xce\xba____\xce\xac\xce\xbb\xce\xbb\xce\xb1___'
'frozenset___%CE%B3%E1%BD%B0%CF%81____%E1%BC%94%CF%86%CE%B7____%CF%80%CF%8C%CE%BB%CE%B9%CE%BD____%E1%BC%90%CE%BB%CF%80%E1%BD%B6%CF%82____%CE%BA%CE%B1%CE%BA%CE%AC____%E1%BC%94%CE%BB%CE%B1%CE%B2%CE%BF%CE%BD____%CE%BF%E1%BD%90%CE%BA____%CE%AC%CE%BB%CE%BB%CE%B1___'

https://stackoverflow.com/questions/5960751/encode-file-path-properly-using-python

En el config, estoy poniendo topics 0, esto significará que LDA lo hará de forma automática

https://radimrehurek.com/gensim/corpora/dictionary.html

cross validation

reorganizar el dataset sin morir en el intento porque no hay memoria suficiente
https://en.wikipedia.org/wiki/Schwartzian_transform

Por limitaciones del PC no he podido realizar un shuffle de los datos
